{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d5e3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:33.520045Z",
     "start_time": "2023-10-07T15:52:33.391071Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22011899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:35.277266Z",
     "start_time": "2023-10-07T15:52:35.260123Z"
    }
   },
   "outputs": [],
   "source": [
    "#settings (do not change it)\n",
    "\n",
    "n_context = 5\n",
    "all_passage_set = set([1,2,3,4,5])\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
    "\n",
    "def ems(prediction, ground_truths):\n",
    "    return max([exact_match_score(prediction, gt) for gt in ground_truths])\n",
    "\n",
    "def find_first_tok_score(prediction):\n",
    "    answer_flag = False\n",
    "    colon_flag = False\n",
    "    for tok, score in zip(prediction['choices'][0]['logprobs']['tokens'],prediction['choices'][0]['logprobs']['token_logprobs']):\n",
    "        if \"answer\" in tok or \"Answer\" in tok:\n",
    "            answer_flag = True\n",
    "        elif \":\" in tok and answer_flag==True:\n",
    "            colon_flag = True\n",
    "        elif answer_flag == True and colon_flag == True:\n",
    "            return tok.strip(), score #pert\n",
    "    return prediction['choices'][0]['logprobs']['tokens'][0].strip(), prediction['choices'][0]['logprobs']['token_logprobs'][0] #no pert or fid pert\n",
    "\n",
    "def em_calc(predictions, n_sample = -1):\n",
    "    predictions_refined = []\n",
    "    for predidx, pred in enumerate(predictions):\n",
    "        pred = pred['choices'][0]['text'].strip()\n",
    "        if \"answer:\" in pred:\n",
    "            predictions_refined.append(pred[pred.find(\"answer:\")+8:])\n",
    "        elif \"Answer:\" in pred:\n",
    "            predictions_refined.append(pred[pred.find(\"Answer:\")+8:])\n",
    "        else:\n",
    "            predictions_refined.append(pred)\n",
    "    em_score = np.mean([ems(pred, sample_answers[i]) for i, pred in enumerate(predictions_refined[:n_sample])])\n",
    "    return em_score\n",
    "\n",
    "def em_calc_first_token_sum_ensemble(predictions_list, n_sample = -1):\n",
    "    n_pred = len(predictions_list)\n",
    "    predictions_refined = []\n",
    "    \n",
    "    for idx_ins in range(n_sample):\n",
    "        dict_first2_ans_score = dict()\n",
    "        for idx_pred in range(n_pred):\n",
    "            pred = predictions_list[idx_pred][idx_ins]['choices'][0]['text'].strip()\n",
    "            \n",
    "            if \"answer:\" in pred:\n",
    "                pred = pred[pred.find(\"answer:\")+8:]\n",
    "            elif \"Answer:\" in pred:\n",
    "                pred = pred[pred.find(\"Answer:\")+8:]\n",
    "            \n",
    "            first_tok, first_score = find_first_tok_score(predictions_list[idx_pred][idx_ins])\n",
    "            if first_tok in dict_first2_ans_score:\n",
    "                if len(pred) > len(dict_first2_ans_score[first_tok][0]):\n",
    "                    pred = dict_first2_ans_score[first_tok][0] # 더 짧은 답 선호\n",
    "                dict_first2_ans_score[first_tok] = (pred, dict_first2_ans_score[first_tok][1] + first_score)\n",
    "            else:\n",
    "                dict_first2_ans_score[first_tok] = (pred, first_score)\n",
    "        \n",
    "        max_score = -999\n",
    "        for first_tok in dict_first2_ans_score:\n",
    "            if dict_first2_ans_score[first_tok][1] > max_score:\n",
    "                max_pred = dict_first2_ans_score[first_tok][0]\n",
    "                max_score = dict_first2_ans_score[first_tok][1]\n",
    "        \n",
    "        predictions_refined.append(max_pred)\n",
    "    \n",
    "    em_score = np.mean([ems(pred, sample_answers[i]) for i, pred in enumerate(predictions_refined[:n_sample])])\n",
    "    return em_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a522d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:51.840274Z",
     "start_time": "2023-10-07T15:52:51.836357Z"
    }
   },
   "outputs": [],
   "source": [
    "#config\n",
    "\n",
    "is_dev = True #True: dev-256 dataset, False: test dataset\n",
    "\n",
    "use_parametric_only = False #if True, use only parametric setting and ignore below two settings\n",
    "use_pert_aware_instruction = True #True: instructions are perturbation-aware , False: instruction are not perturbation-aware\n",
    "use_discriminator_fid = True #True: inject fid discriminator's prediction results in prompts, False: let GPT-3 to generate perturbation predictions\n",
    "\n",
    "pert_ratio = '35' #perturbation probability ['00', '15', '25', '35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd15d902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:53.449934Z",
     "start_time": "2023-10-07T15:52:53.435465Z"
    }
   },
   "outputs": [],
   "source": [
    "if is_dev:\n",
    "    dataset_path = \"../../DATA/corpus/NQ_eval_longpre_dev_256_new_fix.json\"\n",
    "else:\n",
    "    dataset_path = \"../../DATA/corpus/NQ_eval_longpre_test_fix\"\n",
    "\n",
    "with open(dataset_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "sample_n = len(dataset)\n",
    "sample_answers = [s[\"answers\"] for s in dataset][:sample_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6037a244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:55.350780Z",
     "start_time": "2023-10-07T15:52:55.300212Z"
    }
   },
   "outputs": [],
   "source": [
    "#gpt_outpath = \"GPT3_outputs\"\n",
    "gpt_outpath = \"nq_longpre_GPT_outputs\"\n",
    "filename = \"dev_\" if is_dev else \"test_\"\n",
    "filename += \"para_\" if use_parametric_only else \"semipara_\"\n",
    "\n",
    "if use_parametric_only == False:\n",
    "    filename += \"pert_\" if use_pert_aware_instruction else \"\"\n",
    "    filename += \"fidpred_\" if use_discriminator_fid else \"\"\n",
    "    filename += \"p\" + pert_ratio + \"_\"\n",
    "\n",
    "all_results = []\n",
    "worst_results = []\n",
    "best_results = []\n",
    "sample_result = []\n",
    "\n",
    "ensemble_results = []\n",
    "predictions_list = []\n",
    "\n",
    "for sample_ in [\"sample0\",\"sample1\",\"sample2\",\"sample3\",\"sample4\"]:\n",
    "    fliename_s = filename + sample_ + \".pkl\"\n",
    "    \n",
    "    with open(os.path.join(gpt_outpath, fliename_s), 'rb') as output:\n",
    "        predictions = pickle.load(output)[1:]\n",
    "    sample_result.append(em_calc(predictions, sample_n))\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "all_results.append([sum(sample_result) / len(sample_result)])\n",
    "worst_results.append([min(sample_result)])\n",
    "best_results.append([max(sample_result)])\n",
    "\n",
    "ensemble_results.append([em_calc_first_token_sum_ensemble(predictions_list, sample_n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e5ad8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T15:52:57.000783Z",
     "start_time": "2023-10-07T15:52:56.996722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best/avg/worst: ['0.42578125/0.40703125/0.39453125']\n",
      "ensemble-sum: [0.421875]\n"
     ]
    }
   ],
   "source": [
    "print(\"best/avg/worst: \" + str([str(best) + \"/\" + str(avg) + \"/\" + str(worst) for avg, worst, best in zip(all_results[0], worst_results[0], best_results[0])]))\n",
    "print(\"ensemble-sum: \" + str(ensemble_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3500d5ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T19:07:04.807079Z",
     "start_time": "2023-06-22T19:07:04.803387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best/avg/worst: ['0.2734375/0.25390625/0.2265625']\n",
      "ensemble-sum: [0.26171875]\n"
     ]
    }
   ],
   "source": [
    "print(\"best/avg/worst: \" + str([str(best) + \"/\" + str(avg) + \"/\" + str(worst) for avg, worst, best in zip(all_results[0], worst_results[0], best_results[0])]))\n",
    "print(\"ensemble-sum: \" + str(ensemble_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64119165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T18:20:18.361287Z",
     "start_time": "2023-06-22T18:20:18.357569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best/avg/worst: ['0.27734375/0.2578125/0.2265625']\n",
      "ensemble-sum: [0.2734375]\n"
     ]
    }
   ],
   "source": [
    "print(\"best/avg/worst: \" + str([str(best) + \"/\" + str(avg) + \"/\" + str(worst) for avg, worst, best in zip(all_results[0], worst_results[0], best_results[0])]))\n",
    "print(\"ensemble-sum: \" + str(ensemble_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f8886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ACL2023)",
   "language": "python",
   "name": "acl2023_submission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
